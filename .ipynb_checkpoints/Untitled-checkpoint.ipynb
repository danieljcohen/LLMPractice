{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b459b9a-caaa-4be2-8fdd-1e1a6fe71c60",
   "metadata": {},
   "source": [
    "# Creating a Character Level Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95562c02-b26f-4d7b-879b-38637f47a696",
   "metadata": {},
   "source": [
    "Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ce1e3b-c7c7-488f-acb6-b3fe00dfda9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-29 22:42:27--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M   680KB/s    in 1.6s    \n",
      "\n",
      "2024-06-29 22:42:30 (680 KB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08acb8-5d39-4679-9a07-488e1a845752",
   "metadata": {},
   "source": [
    "Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bc5720-af14-4453-8e94-72f2574a622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding = 'utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9d7477-5d01-4119-836d-d1b4896bc8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset(chars): 1115394 \n",
      "\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dataset(chars): {len(text)} \\n\")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4341740e-9df3-41dc-97bb-ebda5b06927a",
   "metadata": {},
   "source": [
    "Taking unique chars in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4262dbd1-4875-48e2-ac96-7392dcd9d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "vocabSize = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocabSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313bffc-2cf7-4a1f-907b-f765cd9118dc",
   "metadata": {},
   "source": [
    "Mapping from chars to ints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf33099-f560-4a49-8493-bec70213ba0a",
   "metadata": {},
   "source": [
    "# When redoing, do with google SentencePiece or openAI tiktoken\n",
    "\n",
    "subword, unit level tokenizer (not individual chars but not full word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea388ea-f1c4-4368-843f-87f6136249f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}  #dict mapping all chars to their ascii vals\n",
    "itos = {i:ch for i, ch in enumerate(chars)}  #dict mapping all ascii vals(ints) to their chars\n",
    "encode = lambda s: [stoi[c] for c in s] #lambda func encoder --> string to list of ints\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) #decoder --> list of ints to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c3116c-6617-40f5-9b04-ce2b57228d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hello world\"))\n",
    "print(decode(encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba71f71-c06f-41b3-a37f-fcabf57dc229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danielcohen/miniconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246e7c94-32ec-45c3-a9e8-7a0ed94b89c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype = torch.long) #makes the basic datatype in pytorch, like a numpy array\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4cdd49-796a-4b5d-830b-e574389c90cf",
   "metadata": {},
   "source": [
    "Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d471f8-01d6-48cf-9be6-b6ce61372e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(.9 * len(data))\n",
    "trainData = data[:n]\n",
    "valData = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6194a-bb6b-4c56-835d-8a4ee52a93e9",
   "metadata": {},
   "source": [
    "Start of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1db048a-3efa-4f9e-8fad-2f3ff4cfaa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockSize = 8 #maximum length of str to input into model at a time\n",
    "trainData[:blockSize + 1] #plus one because there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d21a459-5c84-4a22-983f-02a9e1f4854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target: 18\n",
      "When input is tensor([18, 47]) the target: 47\n",
      "When input is tensor([18, 47, 56]) the target: 56\n",
      "When input is tensor([18, 47, 56, 57]) the target: 57\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target: 58\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target: 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 47\n"
     ]
    }
   ],
   "source": [
    "x = trainData[:blockSize] #inputs to the transformer (first block size chars)\n",
    "y = trainData[:blockSize + 1] #targets for each positions in the inputs\n",
    "for t in range(blockSize):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context} the target: {target}\")\n",
    "\n",
    "#transformer will never recieve more than blocksize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65122c1e-56ba-45dd-8e7e-1fbc7c0662f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[46, 43, 56,  1, 44, 53, 56,  1],\n",
      "        [58, 46, 43,  1, 42, 59, 49, 43],\n",
      "        [50, 57,  6,  0, 26, 53, 58,  1],\n",
      "        [53, 56, 49,  8,  0,  0, 19, 24]])\n",
      "Targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 56,  1, 44, 53, 56,  1, 43],\n",
      "        [46, 43,  1, 42, 59, 49, 43,  8],\n",
      "        [57,  6,  0, 26, 53, 58,  1, 61],\n",
      "        [56, 49,  8,  0,  0, 19, 24, 27]])\n",
      "\n",
      "--------------------------------\n",
      "When input is [46] the target: 43\n",
      "When input is [46, 43] the target: 56\n",
      "When input is [46, 43, 56] the target: 1\n",
      "When input is [46, 43, 56, 1] the target: 44\n",
      "When input is [46, 43, 56, 1, 44] the target: 53\n",
      "When input is [46, 43, 56, 1, 44, 53] the target: 56\n",
      "When input is [46, 43, 56, 1, 44, 53, 56] the target: 1\n",
      "When input is [46, 43, 56, 1, 44, 53, 56, 1] the target: 43\n",
      "When input is [58] the target: 46\n",
      "When input is [58, 46] the target: 43\n",
      "When input is [58, 46, 43] the target: 1\n",
      "When input is [58, 46, 43, 1] the target: 42\n",
      "When input is [58, 46, 43, 1, 42] the target: 59\n",
      "When input is [58, 46, 43, 1, 42, 59] the target: 49\n",
      "When input is [58, 46, 43, 1, 42, 59, 49] the target: 43\n",
      "When input is [58, 46, 43, 1, 42, 59, 49, 43] the target: 8\n",
      "When input is [50] the target: 57\n",
      "When input is [50, 57] the target: 6\n",
      "When input is [50, 57, 6] the target: 0\n",
      "When input is [50, 57, 6, 0] the target: 26\n",
      "When input is [50, 57, 6, 0, 26] the target: 53\n",
      "When input is [50, 57, 6, 0, 26, 53] the target: 58\n",
      "When input is [50, 57, 6, 0, 26, 53, 58] the target: 1\n",
      "When input is [50, 57, 6, 0, 26, 53, 58, 1] the target: 61\n",
      "When input is [53] the target: 56\n",
      "When input is [53, 56] the target: 49\n",
      "When input is [53, 56, 49] the target: 8\n",
      "When input is [53, 56, 49, 8] the target: 0\n",
      "When input is [53, 56, 49, 8, 0] the target: 0\n",
      "When input is [53, 56, 49, 8, 0, 0] the target: 19\n",
      "When input is [53, 56, 49, 8, 0, 0, 19] the target: 24\n",
      "When input is [53, 56, 49, 8, 0, 0, 19, 24] the target: 27\n"
     ]
    }
   ],
   "source": [
    "#batches, process multiple chunks independently at the same time\n",
    "torch.manual_seed(360)\n",
    "batchSize = 4    #how many sequences processed in paralel\n",
    "blockSize = 8    #max context length for predictions\n",
    "\n",
    "def getBatch(split):\n",
    "    \"\"\"\n",
    "    Function that generates a small batch of \n",
    "    data of inputs x and targets y\n",
    "    \"\"\"\n",
    "    if split == 'train':\n",
    "        data = trainData\n",
    "    else:\n",
    "        valData\n",
    "\n",
    "    ix = torch.randint(len(data) - blockSize, (batchSize,)) #4 randomly generated numbers that are offsets into the training setss\n",
    "    x = torch.stack([data[i:i + blockSize] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + blockSize + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = getBatch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('Targets: ')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print()\n",
    "print ('--------------------------------')\n",
    "\n",
    "for b in range(batchSize): # batch dimension\n",
    "    for t in range(blockSize): # time dimension\n",
    "        context = xb[b, : t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"When input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838714c5-5f0e-42f0-a4ff-54b6832b62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[46, 43, 56,  1, 44, 53, 56,  1],\n",
      "        [58, 46, 43,  1, 42, 59, 49, 43],\n",
      "        [50, 57,  6,  0, 26, 53, 58,  1],\n",
      "        [53, 56, 49,  8,  0,  0, 19, 24]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our inpit to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7def8ab6-a94a-45c2-8eac-61fd5716656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.6558, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "DU'i$VEXYXFgS;xWPxFrePG;$Erj3HxEQRgtCl\n",
      "\n",
      "QujbwQUuBW bGKXJN$IDAJ lPd$EJFbQFfkT:;AQEadXR:UuJSeKwQyQIDBR\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(360)\n",
    "\n",
    "\"\"\"\n",
    "B: Batch size. This is the number of sequences processed in parallel during training or inference. The number of sequences in a single batch.\n",
    "\n",
    "T: Time steps. This is the length of each sequence or the number of tokens in each sequence. Often corresponds to the number of words or characters in a sequence.\n",
    "\n",
    "C: Channel size. This is the size of the embedding for each token in the sequence. Csorresponds to the vocabulary size because the embeddings are of size vocabSize.\n",
    "\"\"\"\n",
    "\n",
    "class BigramLanguageModel(nn.Module): #simplest language model\n",
    "\n",
    "    def __init__(self, vocabSize):\n",
    "        super().__init__()\n",
    "        #token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocabSize, vocabSize)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(Batch, Time, Channel (vocabSize))\n",
    "        #logits = scores for next char in the series\n",
    "\n",
    "        #transform logits, targets shape to better conform to what pytorch expects \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # - log likelihood loss (cross-entropy)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    #history is not used right now, but will be used later\n",
    "    def generate(self, idx, maxNewTokens):\n",
    "        #idx is (B, T) array of indices in curr context\n",
    "        for _ in range(maxNewTokens):\n",
    "            logits, loss = self(idx) # get the new preds (logits)\n",
    "            logits = logits[:, -1, :] #transforms from B, C to B, T, C\n",
    "            probs = F.softmax(logits, dim=-1) #apply softmax to get probs\n",
    "            idxNext = torch.multinomial(probs, num_samples = 1) # sample from the distr (B, 1)\n",
    "            idx = torch.cat((idx, idxNext), dim=1) #append samled index to running seq(B, T + 1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocabSize)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype = torch.long) #creating  a tensore (batch = 1x time = 1), initialized with 0\n",
    "print(decode(m.generate(idx, maxNewTokens=100)[0].tolist())) # asking for 100 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38abfec5-f106-448b-a409-ed64673fee4d",
   "metadata": {},
   "source": [
    "Output is really bad because this a totally random model, now train this models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07f68f8-3293-4172-b886-d4130fb43b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pytorch optimzer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) #AdamW as opposed to SGD, more advanced and popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0068145-a6ce-40bd-91ec-cbc9131f7dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3918263912200928\n"
     ]
    }
   ],
   "source": [
    "batchSize = 32\n",
    "for steps in range(10000):\n",
    "\n",
    "    #sample a batch of data\n",
    "    xb, yb = getBatch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4fc844-5552-4e12-9844-e0c90dce4072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A:\n",
      "MNIIOUSThilai-alyond al'dot ferafaind he, r an as! thelll!\n",
      "INGS:\n",
      "\n",
      "Hor, pet fig y ls wr s,\n",
      "has bl EDE:\n",
      "s ises:\n",
      "\n",
      "f keh sck howitiders LOfat thisewive heshanar llincark intoun, The ireshe chepus\n",
      "TRCKllle mu; de, gaus then,\n",
      "Card nexd olllil thanowfaput sthe, nghyrmy evess, athakeveady d 'd\n",
      "MEOnde aterenaped, alo trof t ouce he llser th.\n",
      "mouren! k t,\n",
      "ENESiorved th whird p\n",
      "MBUToutof otoristhe wh nd \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype = torch.long) #creating  a tensore (batch = 1x time = 1), initialized with 0\n",
    "print(decode(m.generate(idx, maxNewTokens=400)[0].tolist())) # asking for 100 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d0c36-a940-42d4-a2e6-0184eeb056d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
